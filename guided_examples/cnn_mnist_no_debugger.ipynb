{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# CNN MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing functions from python3 to python2\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "#importing numpy and tensorflow\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "#ignore all the warnings and don't show them in the notebook\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#treshold on what messages are to be logged\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "#importing debug library\n",
    "from tensorflow.python import debug as tf_debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugger\n",
    "\n",
    "### Uncomment the below line and execute the code to run the debugger.\n",
    "\n",
    "### Go to the link once you start execution    \t\t\thttp://localhost:6006/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment the below line to run the debugger\n",
    "#Add monitor=[hook] as a parameter to the estimators below\n",
    "# hook = tf_debug.TensorBoardDebugHook(\"localhost:6064\")\n",
    "import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model_fn(features, labels, mode):\n",
    "    \"\"\"Model function for CNN.\"\"\"\n",
    "    # Input Layer\n",
    "    # Reshape X to 4-D tensor: [batch_size, width, height, channels]\n",
    "    # MNIST images are 28x28 pixels, and have one color channel\n",
    "    input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n",
    "\n",
    "    # Convolutional Layer #1\n",
    "    # Computes 32 features using a 5x5 filter with ReLU activation.\n",
    "    # Padding is added to preserve width and height.\n",
    "    # Input Tensor Shape: [batch_size, 28, 28, 1]\n",
    "    # Output Tensor Shape: [batch_size, 28, 28, 32]\n",
    "    conv1 = tf.layers.conv2d(\n",
    "        inputs=input_layer,\n",
    "        filters=32,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "\n",
    "    # Pooling Layer #1\n",
    "    # First max pooling layer with a 2x2 filter and stride of 2\n",
    "    # Input Tensor Shape: [batch_size, 28, 28, 32]\n",
    "    # Output Tensor Shape: [batch_size, 14, 14, 32]\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    # Convolutional Layer #2\n",
    "    # Computes 64 features using a 5x5 filter.\n",
    "    # Padding is added to preserve width and height.\n",
    "    # Input Tensor Shape: [batch_size, 14, 14, 32]\n",
    "    # Output Tensor Shape: [batch_size, 14, 14, 64]\n",
    "    conv2 = tf.layers.conv2d(\n",
    "        inputs=pool1,\n",
    "        filters=64,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "\n",
    "    # Pooling Layer #2\n",
    "    # Second max pooling layer with a 2x2 filter and stride of 2\n",
    "    # Input Tensor Shape: [batch_size, 14, 14, 64]\n",
    "    # Output Tensor Shape: [batch_size, 7, 7, 64]\n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    # Flatten tensor into a batch of vectors\n",
    "    # Input Tensor Shape: [batch_size, 7, 7, 64]\n",
    "    # Output Tensor Shape: [batch_size, 7 * 7 * 64]\n",
    "    pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "\n",
    "    # Dense Layer\n",
    "    # Densely connected layer with 1024 neurons\n",
    "    # Input Tensor Shape: [batch_size, 7 * 7 * 64]\n",
    "    # Output Tensor Shape: [batch_size, 1024]\n",
    "    dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "\n",
    "    # Add dropout operation; 0.6 probability that element will be kept\n",
    "    dropout = tf.layers.dropout(\n",
    "            inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "    # Logits layer\n",
    "    # Input Tensor Shape: [batch_size, 1024]\n",
    "    # Output Tensor Shape: [batch_size, 10]\n",
    "    logits = tf.layers.dense(inputs=dropout, units=10)\n",
    "\n",
    "    predictions = {\n",
    "        # Generate predictions (for PREDICT and EVAL mode)\n",
    "        \"classes\": tf.argmax(input=logits, axis=1),\n",
    "        # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "        # `logging_hook`.\n",
    "        \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "      }\n",
    "    #if predict mode, run the estimator and return the values\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "    # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "    # Configure the Training Op (for TRAIN mode)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "    # Add evaluation metrics (for EVAL mode)\n",
    "    eval_metric_ops = {\n",
    "        \"accuracy\": tf.metrics.accuracy(\n",
    "            labels=labels, predictions=predictions[\"classes\"])}\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(unused_argv):\n",
    "    # Load training data\n",
    "    mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
    "    train_data = mnist.train.images  # Returns np.array\n",
    "    #load the the train data labels\n",
    "    train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "    #load the test data\n",
    "    eval_data = mnist.test.images  # Returns np.array\n",
    "    #load the test data labels\n",
    "    eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)\n",
    "    \n",
    "    # Create the Estimator\n",
    "    mnist_classifier = tf.estimator.Estimator(\n",
    "        model_fn=cnn_model_fn, model_dir=\"/tmp/mnist_convnet_model\")\n",
    "\n",
    "    # Set up logging for predictions\n",
    "    # Log the values in the \"Softmax\" tensor with label \"probabilities\"\n",
    "    tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "    logging_hook = tf.train.LoggingTensorHook(\n",
    "        tensors=tensors_to_log, every_n_iter=50)\n",
    "\n",
    "    # Train the model\n",
    "    train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x={\"x\": train_data},\n",
    "        y=train_labels,\n",
    "        batch_size=100,\n",
    "        num_epochs=None,\n",
    "        shuffle=True)\n",
    "    mnist_classifier.train(\n",
    "        input_fn=train_input_fn,\n",
    "        steps=200,\n",
    "        hooks=[logging_hook])\n",
    "\n",
    "    # Evaluate the model and print results\n",
    "    eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x={\"x\": eval_data},\n",
    "        y=eval_labels,\n",
    "        num_epochs=1,\n",
    "        shuffle=False)\n",
    "    eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "    print(eval_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-2c8f4bafec7a>:3: load_dataset (from tensorflow.contrib.learn.python.learn.datasets) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data.\n",
      "WARNING:tensorflow:From c:\\users\\7178185\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\__init__.py:80: load_mnist (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From c:\\users\\7178185\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:300: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From c:\\users\\7178185\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From c:\\users\\7178185\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST-data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\users\\7178185\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST-data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\users\\7178185\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/mnist_convnet_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001D12DD654E0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/mnist_convnet_model\\model.ckpt-200\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 200 into /tmp/mnist_convnet_model\\model.ckpt.\n",
      "INFO:tensorflow:probabilities = [[0.12206484 0.10264874 0.08619478 0.09880631 0.08767601 0.1021915\n",
      "  0.10108991 0.09711574 0.10848875 0.09372348]\n",
      " [0.11677815 0.11078656 0.10050582 0.09244408 0.09825438 0.10263219\n",
      "  0.09104946 0.09864854 0.09059779 0.09830303]\n",
      " [0.11149653 0.1076544  0.09885786 0.10199746 0.0942104  0.09866386\n",
      "  0.08961834 0.09777134 0.10037952 0.09935035]\n",
      " [0.10606106 0.10229126 0.09590978 0.1025826  0.09488048 0.09721354\n",
      "  0.09300896 0.10794921 0.09955627 0.10054686]\n",
      " [0.11031557 0.11074238 0.10034344 0.0976498  0.09122229 0.09257361\n",
      "  0.0898778  0.10225686 0.10277419 0.10224413]\n",
      " [0.10524678 0.10001171 0.09727836 0.09395168 0.09026993 0.10895669\n",
      "  0.09341042 0.09817584 0.11062779 0.10207091]\n",
      " [0.0998911  0.10661418 0.10784259 0.09860037 0.09827267 0.09693252\n",
      "  0.10010526 0.09804942 0.0974883  0.09620357]\n",
      " [0.10404671 0.11662449 0.10028184 0.10342289 0.08858369 0.09159992\n",
      "  0.10037418 0.09914111 0.09439209 0.1015332 ]\n",
      " [0.11190537 0.10553853 0.10821779 0.09207339 0.09691253 0.09360946\n",
      "  0.09854808 0.09273103 0.10462999 0.09583385]\n",
      " [0.10002902 0.09845346 0.10533556 0.09836596 0.09001167 0.09440468\n",
      "  0.09858822 0.0946556  0.1084078  0.11174798]\n",
      " [0.11742618 0.10022356 0.09791899 0.11555119 0.09442659 0.09425184\n",
      "  0.09022581 0.09114262 0.10254924 0.09628394]\n",
      " [0.11399322 0.10194465 0.09786724 0.09262932 0.08767755 0.1069517\n",
      "  0.09848902 0.09450756 0.10426887 0.10167087]\n",
      " [0.11987603 0.10864943 0.09523281 0.10125984 0.09416031 0.09050152\n",
      "  0.09990451 0.09190582 0.10684169 0.09166799]\n",
      " [0.10190107 0.10341207 0.09183213 0.10456733 0.09157801 0.09977851\n",
      "  0.10311201 0.10096156 0.0991634  0.10369394]\n",
      " [0.11737718 0.10033619 0.0912708  0.11205354 0.09240767 0.08917248\n",
      "  0.10681754 0.09466592 0.10202675 0.09387191]\n",
      " [0.11686697 0.1087328  0.10076585 0.0950744  0.09379998 0.09365705\n",
      "  0.09628667 0.09573049 0.10431374 0.0947721 ]\n",
      " [0.10753142 0.09563865 0.09885417 0.10602189 0.09691367 0.09394608\n",
      "  0.09799475 0.09948537 0.10380355 0.0998105 ]\n",
      " [0.11680157 0.1004878  0.10609116 0.09550554 0.09756532 0.10195041\n",
      "  0.10695807 0.0873487  0.09101826 0.09627304]\n",
      " [0.09633274 0.10862134 0.09932023 0.1056258  0.09871653 0.09753802\n",
      "  0.08679794 0.09807997 0.11005338 0.09891403]\n",
      " [0.11242297 0.11063214 0.09075174 0.10490922 0.10340149 0.08856271\n",
      "  0.10001472 0.09921179 0.09032114 0.099772  ]\n",
      " [0.09576841 0.09548541 0.09763847 0.09330631 0.10813944 0.09951493\n",
      "  0.09137225 0.09591942 0.11080355 0.11205184]\n",
      " [0.11120644 0.09960787 0.09793179 0.08833833 0.09315158 0.10249211\n",
      "  0.10704394 0.08856208 0.10382334 0.10784253]\n",
      " [0.11366794 0.09844863 0.10164395 0.10195788 0.09417854 0.10081603\n",
      "  0.08813057 0.09721816 0.107171   0.0967673 ]\n",
      " [0.10895774 0.1129436  0.09998807 0.10597827 0.09017609 0.08524113\n",
      "  0.09913609 0.09546874 0.10395356 0.09815666]\n",
      " [0.11276221 0.11053063 0.10437695 0.10236964 0.08899187 0.08663549\n",
      "  0.09455538 0.10013002 0.10218277 0.09746504]\n",
      " [0.10573288 0.10929283 0.09327835 0.10069513 0.09531077 0.09972835\n",
      "  0.09757727 0.10929988 0.09848315 0.0906013 ]\n",
      " [0.11145424 0.10926371 0.09330598 0.09983854 0.09788343 0.0941158\n",
      "  0.09882341 0.08899601 0.10058594 0.10573287]\n",
      " [0.09861264 0.10048407 0.10707714 0.10691701 0.09661451 0.09851135\n",
      "  0.09394092 0.10069475 0.09642144 0.10072614]\n",
      " [0.12502626 0.11419078 0.08984558 0.09521193 0.09464994 0.0860501\n",
      "  0.10078808 0.09377223 0.10297251 0.09749259]\n",
      " [0.1155163  0.11507743 0.08732293 0.10453322 0.08451734 0.09681867\n",
      "  0.1062346  0.09949458 0.09871061 0.09177429]\n",
      " [0.10497856 0.11602344 0.10304392 0.09607706 0.09027085 0.09129146\n",
      "  0.09845369 0.09509192 0.10138994 0.10337923]\n",
      " [0.09650664 0.10934022 0.10388733 0.08935184 0.09115405 0.09873321\n",
      "  0.10405034 0.09587586 0.10448902 0.10661143]\n",
      " [0.09995846 0.10899992 0.09894213 0.10014664 0.09606569 0.09941821\n",
      "  0.09882412 0.09538791 0.09845319 0.10380377]\n",
      " [0.12544638 0.10407339 0.09002826 0.10544462 0.09650239 0.09438954\n",
      "  0.10689105 0.08291286 0.09770379 0.09660778]\n",
      " [0.10303673 0.09777889 0.09011376 0.10269655 0.1086676  0.094656\n",
      "  0.10215005 0.10681853 0.09637742 0.09770451]\n",
      " [0.09438126 0.10712936 0.09816805 0.10069654 0.09848989 0.09962211\n",
      "  0.0963685  0.0935362  0.1073915  0.10421654]\n",
      " [0.10101833 0.10670014 0.10168194 0.09498847 0.10074878 0.10091358\n",
      "  0.0973788  0.09868892 0.09819987 0.09968121]\n",
      " [0.11179172 0.11023284 0.08736958 0.10374922 0.09724429 0.09687829\n",
      "  0.09695797 0.09203403 0.09848043 0.10526161]\n",
      " [0.11709914 0.10869912 0.094007   0.09503458 0.09327833 0.09370027\n",
      "  0.09164528 0.10261865 0.10703034 0.0968872 ]\n",
      " [0.11572744 0.11252845 0.0957268  0.10872386 0.08874314 0.0980939\n",
      "  0.09626225 0.09484367 0.09360243 0.09574809]\n",
      " [0.11441538 0.10330249 0.09516085 0.09903196 0.08431921 0.10148814\n",
      "  0.09946439 0.09863076 0.10433695 0.09984986]\n",
      " [0.11406814 0.10791884 0.09402686 0.10322321 0.0892016  0.10345476\n",
      "  0.09561063 0.09326398 0.10326944 0.09596256]\n",
      " [0.12462003 0.09444087 0.09605553 0.0943104  0.09105235 0.10460169\n",
      "  0.10654317 0.0920665  0.10648726 0.08982223]\n",
      " [0.10457919 0.10338207 0.09482369 0.10527276 0.09750449 0.09497283\n",
      "  0.09265704 0.09593333 0.11092264 0.09995184]\n",
      " [0.11099171 0.11021249 0.10406575 0.10244405 0.08956928 0.09062272\n",
      "  0.09254534 0.10177171 0.10642354 0.09135336]\n",
      " [0.11407129 0.11130945 0.09340373 0.09834038 0.10200145 0.09518523\n",
      "  0.0977273  0.09948546 0.0979336  0.09054211]\n",
      " [0.10237451 0.11212402 0.10880841 0.10093453 0.09430378 0.09123955\n",
      "  0.10054652 0.10199118 0.09214611 0.09553126]\n",
      " [0.11499285 0.10339363 0.09868371 0.10797897 0.10171221 0.09347308\n",
      "  0.0907198  0.0891626  0.09911625 0.10076678]\n",
      " [0.11303674 0.09834923 0.09863972 0.10355239 0.10010175 0.09743752\n",
      "  0.09871376 0.09627832 0.09592287 0.09796772]\n",
      " [0.11360027 0.09891674 0.09293558 0.09184623 0.09088123 0.09807655\n",
      "  0.09865461 0.08751167 0.10791808 0.119659  ]\n",
      " [0.11269457 0.11018846 0.09293448 0.1020994  0.08865505 0.09965353\n",
      "  0.09657927 0.10434201 0.0981459  0.09470718]\n",
      " [0.10573523 0.10239062 0.09714047 0.09131058 0.09270377 0.09389328\n",
      "  0.09303601 0.10997447 0.11261657 0.10119908]\n",
      " [0.10160465 0.10449199 0.09374735 0.09819297 0.10180994 0.10911025\n",
      "  0.09936363 0.09530155 0.10192641 0.09445133]\n",
      " [0.10637207 0.10291641 0.10902445 0.10301425 0.0966114  0.09144378\n",
      "  0.08332141 0.10331623 0.10467624 0.09930384]\n",
      " [0.11924638 0.10746083 0.09758069 0.09394406 0.1047814  0.0952085\n",
      "  0.09427414 0.09652857 0.09264418 0.09833118]\n",
      " [0.11021497 0.11026532 0.09239076 0.10461296 0.0959103  0.0940621\n",
      "  0.10339119 0.08439261 0.10838639 0.09637339]\n",
      " [0.10644759 0.11125492 0.09781773 0.10115999 0.09229519 0.09415218\n",
      "  0.09932756 0.09945066 0.09580652 0.10228765]\n",
      " [0.10631941 0.10666874 0.10271706 0.09378661 0.09682244 0.09891846\n",
      "  0.09596089 0.0892954  0.11197984 0.09753112]\n",
      " [0.09905146 0.11325248 0.10278955 0.10795631 0.08690567 0.10041706\n",
      "  0.09577981 0.09654907 0.09765387 0.09964468]\n",
      " [0.09674791 0.10840248 0.09889024 0.10055808 0.09387588 0.09551834\n",
      "  0.09560801 0.0969777  0.10425286 0.1091684 ]\n",
      " [0.1180261  0.11643478 0.09658449 0.10488866 0.09254588 0.09080437\n",
      "  0.09539695 0.09595439 0.09992009 0.08944425]\n",
      " [0.09872061 0.10127971 0.1117967  0.09496851 0.08676917 0.09514406\n",
      "  0.10030715 0.09512895 0.10855683 0.10732837]\n",
      " [0.11295629 0.10301877 0.0913464  0.11262967 0.09406044 0.09326878\n",
      "  0.09977271 0.09523537 0.10306727 0.09464429]\n",
      " [0.11748523 0.09975977 0.10034491 0.0955576  0.09320688 0.08574212\n",
      "  0.10651148 0.10489663 0.09946481 0.09703057]\n",
      " [0.11140646 0.09348106 0.09364279 0.09880203 0.10050494 0.09780939\n",
      "  0.09960582 0.0889016  0.10824277 0.10760316]\n",
      " [0.11536278 0.09427619 0.09583477 0.09233918 0.09837426 0.10238037\n",
      "  0.09614257 0.09334066 0.1080825  0.10386679]\n",
      " [0.10876128 0.10541112 0.09600543 0.09448844 0.09681094 0.10065839\n",
      "  0.11604484 0.09097511 0.09284487 0.09799962]\n",
      " [0.10922815 0.1008225  0.10305027 0.09302228 0.09889736 0.10414479\n",
      "  0.10268816 0.08723989 0.10704879 0.09385784]\n",
      " [0.10791918 0.10569753 0.0899834  0.1046062  0.0906475  0.10379166\n",
      "  0.09647156 0.10508262 0.0903583  0.10544203]\n",
      " [0.10944373 0.10394373 0.08699201 0.11471511 0.09693524 0.09896224\n",
      "  0.0914757  0.0918971  0.10598307 0.09965201]\n",
      " [0.12313602 0.09314343 0.08687779 0.11709747 0.0988708  0.09525924\n",
      "  0.0992273  0.09022932 0.09853077 0.09762788]\n",
      " [0.12380715 0.10570221 0.08937199 0.10544951 0.0897921  0.08672903\n",
      "  0.11079559 0.08815534 0.09595874 0.10423829]\n",
      " [0.12525664 0.10211733 0.0835302  0.09374548 0.10028142 0.08992296\n",
      "  0.10778987 0.09356514 0.10202381 0.10176705]\n",
      " [0.11719407 0.10364894 0.0975055  0.09172723 0.10300598 0.10607662\n",
      "  0.09763361 0.09528068 0.09094279 0.09698459]\n",
      " [0.10560329 0.11788097 0.10024562 0.09923743 0.08740735 0.08862422\n",
      "  0.09477735 0.10384694 0.10234506 0.1000317 ]\n",
      " [0.10007368 0.10521995 0.09737363 0.09681898 0.09193882 0.10566146\n",
      "  0.10042246 0.09952947 0.10633183 0.09662969]\n",
      " [0.12005287 0.10523077 0.0988673  0.0943184  0.09580662 0.08736285\n",
      "  0.08914311 0.0963636  0.11646537 0.09638911]\n",
      " [0.09079006 0.10072538 0.11050597 0.10882026 0.1007173  0.10468166\n",
      "  0.09745063 0.08680003 0.10424752 0.09526123]\n",
      " [0.11425092 0.11367179 0.09664409 0.09843166 0.09636601 0.09052595\n",
      "  0.10615038 0.09757841 0.09821215 0.08816861]\n",
      " [0.11208878 0.1059384  0.09828123 0.10519551 0.09784099 0.08930143\n",
      "  0.0989055  0.10122033 0.08957897 0.10164882]\n",
      " [0.10625225 0.10738202 0.09388584 0.10641699 0.09970909 0.09965479\n",
      "  0.09390809 0.0967811  0.09192042 0.1040894 ]\n",
      " [0.1115419  0.10835042 0.08962689 0.09567936 0.09417769 0.09366579\n",
      "  0.11074411 0.07876446 0.10904391 0.10840547]\n",
      " [0.10153636 0.10864576 0.09900198 0.0998289  0.09706166 0.09264506\n",
      "  0.09587388 0.09842815 0.10796274 0.09901553]\n",
      " [0.097569   0.10350824 0.09981716 0.09147677 0.09245607 0.10483924\n",
      "  0.11026315 0.09206602 0.1072745  0.10072991]\n",
      " [0.10204358 0.11298599 0.09686637 0.0931127  0.10034064 0.09297658\n",
      "  0.09142473 0.10389581 0.10292306 0.10343052]\n",
      " [0.10356218 0.11150352 0.09928936 0.10462711 0.08993395 0.1001652\n",
      "  0.09802224 0.08855221 0.10270996 0.10163422]\n",
      " [0.1003613  0.10882217 0.09518422 0.09672766 0.09173688 0.10604505\n",
      "  0.0914011  0.10198882 0.10412559 0.10360733]\n",
      " [0.10355849 0.10529101 0.10482043 0.09375309 0.09291759 0.09933074\n",
      "  0.09262091 0.1042536  0.10193019 0.10152404]\n",
      " [0.11368284 0.10683715 0.0991336  0.08987775 0.09706292 0.09987033\n",
      "  0.09544439 0.09464226 0.10696862 0.0964802 ]\n",
      " [0.10917677 0.11506398 0.09995202 0.09495821 0.0870242  0.08777771\n",
      "  0.10133569 0.10530747 0.10171574 0.09768821]\n",
      " [0.11835472 0.10270086 0.09503254 0.10152795 0.09749993 0.08939419\n",
      "  0.10881902 0.09323046 0.10243374 0.0910065 ]\n",
      " [0.09809966 0.10980324 0.10704032 0.1029918  0.08648615 0.10252741\n",
      "  0.1033697  0.0909669  0.09719338 0.10152137]\n",
      " [0.10771258 0.11178161 0.09985328 0.09495247 0.09941244 0.10333218\n",
      "  0.10215832 0.08992297 0.09405515 0.096819  ]\n",
      " [0.11120824 0.10703468 0.10014263 0.09568179 0.0898492  0.10003665\n",
      "  0.1027457  0.09277255 0.09723516 0.10329343]\n",
      " [0.11634921 0.10921522 0.09425202 0.0911408  0.09544456 0.09667959\n",
      "  0.09909109 0.10032701 0.09923998 0.09826043]\n",
      " [0.10880122 0.100957   0.08610978 0.10519466 0.08488229 0.09475238\n",
      "  0.0966259  0.08835389 0.12241413 0.11190882]\n",
      " [0.11524335 0.10356389 0.0988612  0.11025306 0.09857148 0.09061651\n",
      "  0.09468886 0.08787518 0.1059997  0.09432678]\n",
      " [0.10567455 0.10547203 0.09315132 0.10316496 0.08688131 0.09359148\n",
      "  0.09781405 0.10665967 0.09977397 0.10781667]\n",
      " [0.10804767 0.10515437 0.09915017 0.09095883 0.09168003 0.10252661\n",
      "  0.10286819 0.09901226 0.10026309 0.10033868]\n",
      " [0.10598624 0.10195658 0.0963521  0.09629585 0.08927021 0.10650888\n",
      "  0.10684291 0.09326269 0.10579466 0.09772991]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.2763422, step = 201\n",
      "INFO:tensorflow:probabilities = [[0.10545531 0.10635927 0.08974896 0.09320334 0.09953374 0.097153\n",
      "  0.09589889 0.10162999 0.10915956 0.10185806]\n",
      " [0.11278766 0.09426642 0.08174032 0.09262894 0.09326299 0.08982173\n",
      "  0.10270584 0.10893599 0.11982785 0.10402226]\n",
      " [0.10936493 0.10658029 0.11176837 0.09389289 0.08601717 0.08918862\n",
      "  0.10797025 0.0963737  0.1027183  0.09612542]\n",
      " [0.10888703 0.10075003 0.10114063 0.0958903  0.08485499 0.09934626\n",
      "  0.10826171 0.085552   0.10900743 0.10630959]\n",
      " [0.10177691 0.10508612 0.09357838 0.10123185 0.08779202 0.10340195\n",
      "  0.09398383 0.10894009 0.10391164 0.10029725]\n",
      " [0.10816914 0.11322699 0.10703857 0.09258401 0.08966339 0.0924964\n",
      "  0.10121699 0.09741224 0.0973569  0.1008353 ]\n",
      " [0.1227513  0.10212713 0.10438173 0.09432421 0.09563052 0.09459161\n",
      "  0.09668764 0.09752382 0.09950272 0.09247933]\n",
      " [0.10767598 0.10236245 0.10312651 0.10318874 0.09048291 0.0990045\n",
      "  0.09313032 0.09713583 0.10383689 0.10005589]\n",
      " [0.10003439 0.10432301 0.10632401 0.09431192 0.09646991 0.08925819\n",
      "  0.09869383 0.10537593 0.10049821 0.10471067]\n",
      " [0.10692599 0.11059038 0.09428027 0.09221691 0.09379589 0.09462946\n",
      "  0.09882257 0.11123993 0.10268407 0.09481452]\n",
      " [0.1073168  0.10180303 0.09453895 0.10656885 0.09327014 0.10425235\n",
      "  0.10462987 0.09086584 0.09466432 0.10208986]\n",
      " [0.10925648 0.10787802 0.1035386  0.09724916 0.0941516  0.10068257\n",
      "  0.09378254 0.09504775 0.09462134 0.10379196]\n",
      " [0.10323946 0.10579057 0.10312503 0.09700478 0.09469842 0.10304502\n",
      "  0.099598   0.09575671 0.09865917 0.09908287]\n",
      " [0.11491051 0.10373665 0.09460276 0.09925929 0.08877034 0.10028868\n",
      "  0.09687067 0.09439348 0.10145729 0.1057103 ]\n",
      " [0.10628134 0.10966983 0.10129238 0.10211007 0.09076431 0.09183595\n",
      "  0.09319282 0.10207116 0.10574561 0.09703654]\n",
      " [0.1125846  0.10168315 0.09792066 0.09784061 0.09749173 0.09365994\n",
      "  0.09576392 0.1059464  0.10662963 0.0904794 ]\n",
      " [0.1088119  0.1046937  0.10823286 0.10812064 0.0833879  0.0955507\n",
      "  0.09612779 0.08473156 0.11027808 0.1000649 ]\n",
      " [0.11600292 0.09864993 0.09322198 0.10765962 0.09542421 0.09756929\n",
      "  0.10103993 0.09201539 0.0960333  0.10238336]\n",
      " [0.102429   0.10514011 0.10224111 0.09937873 0.1009297  0.10076027\n",
      "  0.0888104  0.09974746 0.09995821 0.10060506]\n",
      " [0.11185752 0.10536762 0.09490655 0.09765178 0.09227128 0.09508424\n",
      "  0.09721816 0.10027424 0.10202916 0.10333943]\n",
      " [0.10094968 0.10694925 0.10202689 0.10082867 0.09391641 0.10345888\n",
      "  0.09345064 0.09560915 0.09978496 0.10302544]\n",
      " [0.1137428  0.10084943 0.0979823  0.10976069 0.08487551 0.09235597\n",
      "  0.10175956 0.0899586  0.10669699 0.102018  ]\n",
      " [0.10244831 0.10362116 0.10037679 0.10439812 0.09330447 0.10275338\n",
      "  0.09366463 0.09116895 0.10699841 0.10126588]\n",
      " [0.12437671 0.10430333 0.09742124 0.10206652 0.09360568 0.09274342\n",
      "  0.09158324 0.09332527 0.10779402 0.09278052]\n",
      " [0.1114842  0.09718536 0.10125745 0.09904131 0.09316713 0.09695856\n",
      "  0.11064493 0.09322131 0.10388137 0.09315841]\n",
      " [0.11592037 0.10411717 0.08925818 0.09326146 0.08990452 0.1022815\n",
      "  0.12149189 0.08698265 0.0996898  0.09709243]\n",
      " [0.10857901 0.11626932 0.09428301 0.0915397  0.09820165 0.0890379\n",
      "  0.09736421 0.10353079 0.10227426 0.09892023]\n",
      " [0.12136226 0.10411996 0.09395735 0.08858716 0.08857152 0.09603462\n",
      "  0.10207001 0.10724351 0.10347468 0.09457897]\n",
      " [0.12954935 0.09246539 0.0862719  0.10849858 0.08857283 0.09315883\n",
      "  0.09854734 0.09009133 0.11089147 0.10195296]\n",
      " [0.10905472 0.10962984 0.10066569 0.10151754 0.08633253 0.09210098\n",
      "  0.10111871 0.09356397 0.10562109 0.10039482]\n",
      " [0.10535899 0.10955075 0.10718214 0.09699555 0.08798259 0.10420877\n",
      "  0.09525175 0.08557054 0.10718288 0.10071613]\n",
      " [0.10483801 0.101855   0.09760728 0.10946997 0.09397174 0.10214897\n",
      "  0.09289247 0.09478384 0.0977157  0.10471703]\n",
      " [0.0992446  0.10860108 0.09256265 0.09601338 0.10351242 0.10553898\n",
      "  0.09200142 0.10356826 0.09479861 0.10415851]\n",
      " [0.1087437  0.10496042 0.10323624 0.0938118  0.08496162 0.1022915\n",
      "  0.09793717 0.09100549 0.11160596 0.10144606]\n",
      " [0.10162409 0.10217212 0.09566104 0.11524786 0.09786124 0.09501214\n",
      "  0.0980674  0.10339822 0.09995582 0.09100007]\n",
      " [0.11222143 0.10658105 0.09504821 0.09643947 0.09101211 0.09616115\n",
      "  0.10195599 0.09048887 0.10339299 0.1066987 ]\n",
      " [0.09834862 0.1050932  0.10310246 0.1024706  0.08933964 0.10023231\n",
      "  0.09544698 0.09556857 0.10100577 0.10939173]\n",
      " [0.09994426 0.10547653 0.0946634  0.09825843 0.09366785 0.09077609\n",
      "  0.10985795 0.09534648 0.10645495 0.10555414]\n",
      " [0.10018463 0.10084678 0.09660651 0.09260258 0.10169484 0.10292766\n",
      "  0.09778958 0.09409129 0.10987822 0.10337788]\n",
      " [0.11056718 0.10875903 0.09565344 0.09720606 0.09292077 0.09807165\n",
      "  0.11144725 0.09219605 0.09435415 0.09882434]\n",
      " [0.12116296 0.09137046 0.09893836 0.10134472 0.09887645 0.1020414\n",
      "  0.09110717 0.10523907 0.09327555 0.09664388]\n",
      " [0.11996597 0.10903779 0.08789126 0.09628703 0.09903371 0.09453413\n",
      "  0.09616463 0.10154741 0.09850265 0.09703549]\n",
      " [0.1020686  0.10500185 0.10342719 0.09784872 0.099015   0.11181373\n",
      "  0.09288341 0.08690128 0.10171627 0.09932394]\n",
      " [0.09957937 0.10402744 0.09826751 0.10094485 0.10130727 0.09904804\n",
      "  0.08853836 0.10266842 0.10195966 0.10365903]\n",
      " [0.11419058 0.10729671 0.10054119 0.09283538 0.09093058 0.09721357\n",
      "  0.10572576 0.08894595 0.10008307 0.10223729]\n",
      " [0.11436915 0.09934165 0.08616597 0.10944462 0.09307607 0.09647492\n",
      "  0.10107594 0.09700219 0.10036068 0.10268881]\n",
      " [0.10879784 0.1074472  0.11349002 0.10444725 0.08622639 0.10006765\n",
      "  0.0925891  0.08593372 0.09712897 0.10387186]\n",
      " [0.10604797 0.10550439 0.10146242 0.11026847 0.09149347 0.09397306\n",
      "  0.09289788 0.10309866 0.0977345  0.09751912]\n",
      " [0.10935592 0.10360676 0.10025544 0.09995155 0.09234075 0.09634826\n",
      "  0.09626735 0.09894318 0.11085083 0.0920799 ]\n",
      " [0.11108997 0.1087221  0.10004303 0.09944967 0.0906023  0.10061446\n",
      "  0.09552594 0.09254717 0.10282151 0.09858374]\n",
      " [0.09823942 0.10547189 0.10115793 0.09980833 0.10088772 0.09732616\n",
      "  0.09779825 0.09894569 0.10636162 0.09400311]\n",
      " [0.10862716 0.09785313 0.09360609 0.09878118 0.09846511 0.0977195\n",
      "  0.10041937 0.09507577 0.10899328 0.10045942]\n",
      " [0.11029583 0.10051505 0.09270394 0.09986751 0.09797461 0.10531349\n",
      "  0.09032373 0.09952603 0.10033757 0.10314222]\n",
      " [0.10698552 0.09472816 0.10154583 0.09930765 0.09689198 0.09086448\n",
      "  0.10909881 0.10859795 0.09479221 0.09718732]\n",
      " [0.09960659 0.10306417 0.09722303 0.09843247 0.09339374 0.09994287\n",
      "  0.09715103 0.10504033 0.10401627 0.10212957]\n",
      " [0.11782528 0.09494003 0.10479458 0.10287861 0.09730542 0.0890792\n",
      "  0.09817575 0.10035067 0.100751   0.09389944]\n",
      " [0.114334   0.10039111 0.10986461 0.1023127  0.08832797 0.09717052\n",
      "  0.10143233 0.08422611 0.1020632  0.09987747]\n",
      " [0.10274217 0.10454553 0.10807807 0.087332   0.09723899 0.09953713\n",
      "  0.10520165 0.10018784 0.10293906 0.0921976 ]\n",
      " [0.11802483 0.10277695 0.09281433 0.08958361 0.09520175 0.09444954\n",
      "  0.11069594 0.09987681 0.10409179 0.09248441]\n",
      " [0.1191518  0.10012367 0.08744936 0.09900936 0.08984552 0.08882683\n",
      "  0.10676898 0.09514232 0.1112699  0.10241227]\n",
      " [0.11564004 0.10901736 0.09652586 0.11405733 0.09099243 0.08867746\n",
      "  0.09643112 0.08729753 0.09811763 0.10324326]\n",
      " [0.11109643 0.10564607 0.09894411 0.11798937 0.08871592 0.0926858\n",
      "  0.09243483 0.09746096 0.10108164 0.09394488]\n",
      " [0.10223451 0.11581188 0.10336671 0.11360422 0.09021463 0.09544244\n",
      "  0.09197368 0.09271484 0.09676175 0.0978753 ]\n",
      " [0.11187935 0.10984611 0.09982628 0.0969684  0.09498011 0.09433671\n",
      "  0.09542779 0.09661347 0.10359684 0.09652496]\n",
      " [0.10926712 0.10487775 0.10153406 0.10548177 0.09563186 0.09341866\n",
      "  0.09901614 0.0974232  0.09518401 0.0981654 ]\n",
      " [0.10532659 0.10466112 0.09711596 0.09485056 0.10397188 0.09288547\n",
      "  0.09776501 0.1003251  0.10526273 0.09783556]\n",
      " [0.11784038 0.10118316 0.09517419 0.09856755 0.09518145 0.10741217\n",
      "  0.09365901 0.09878769 0.10156515 0.09062927]\n",
      " [0.12985128 0.08946296 0.09617458 0.11188818 0.08495502 0.09108235\n",
      "  0.09985788 0.08758895 0.11070589 0.09843297]\n",
      " [0.11209734 0.10567488 0.09574211 0.10449459 0.10733993 0.09309655\n",
      "  0.09842471 0.08646271 0.10505506 0.09161217]\n",
      " [0.11353868 0.09614994 0.10417237 0.10037782 0.08979329 0.09269888\n",
      "  0.10160806 0.09093425 0.11131395 0.09941267]\n",
      " [0.10023116 0.10628041 0.10138847 0.10317767 0.09919789 0.09630689\n",
      "  0.10049051 0.09948266 0.09345388 0.09999053]\n",
      " [0.10261525 0.10505731 0.10899468 0.09124574 0.10598011 0.09861475\n",
      "  0.09120556 0.09225776 0.09515868 0.10887014]\n",
      " [0.10589405 0.10959407 0.10531536 0.10535455 0.08608122 0.08864921\n",
      "  0.10809311 0.10095628 0.09723219 0.09282994]\n",
      " [0.11777146 0.10491604 0.10108747 0.11524944 0.09904489 0.09914102\n",
      "  0.09269203 0.08895923 0.09203157 0.0891068 ]\n",
      " [0.12204054 0.10227452 0.08950175 0.10341863 0.10147082 0.09749182\n",
      "  0.08719713 0.10504255 0.10040966 0.09115244]\n",
      " [0.10389189 0.10236281 0.10532508 0.09668464 0.08664012 0.09831965\n",
      "  0.09361885 0.10006172 0.10923379 0.10386134]\n",
      " [0.09977708 0.11413655 0.09144673 0.10358083 0.09517601 0.09357151\n",
      "  0.09397873 0.09903096 0.10376452 0.10553706]\n",
      " [0.11227548 0.10851961 0.09789755 0.094891   0.09637746 0.09366528\n",
      "  0.09243284 0.09951749 0.09787516 0.10654808]\n",
      " [0.1153798  0.09082349 0.09962309 0.0902645  0.09541691 0.09979171\n",
      "  0.11362836 0.10005035 0.10240031 0.0926214 ]\n",
      " [0.10998651 0.0995861  0.10142913 0.10789375 0.09635313 0.09832239\n",
      "  0.08643211 0.09548273 0.09325596 0.11125813]\n",
      " [0.10202744 0.10243775 0.09977351 0.11042553 0.08658189 0.09034894\n",
      "  0.10767014 0.09290186 0.10742519 0.10040771]\n",
      " [0.10477734 0.10692997 0.09402425 0.09636278 0.0944468  0.0892927\n",
      "  0.11693458 0.09395841 0.10110603 0.10216717]\n",
      " [0.10861332 0.11495005 0.10246237 0.09106907 0.09082033 0.09242824\n",
      "  0.09223732 0.1057294  0.10281635 0.09887357]\n",
      " [0.11964337 0.11059562 0.08544052 0.09805153 0.09412716 0.08516616\n",
      "  0.10339022 0.08643702 0.1097779  0.10737063]\n",
      " [0.10104708 0.11272047 0.10357936 0.10144082 0.09724818 0.09579641\n",
      "  0.08715851 0.09977005 0.10101957 0.10021958]\n",
      " [0.1053431  0.10106597 0.09486166 0.09189741 0.10473727 0.09679418\n",
      "  0.1046684  0.09079331 0.10464706 0.10519156]\n",
      " [0.11605146 0.10535582 0.09273998 0.1150178  0.09197097 0.08406021\n",
      "  0.09386998 0.10372167 0.09604812 0.10116395]\n",
      " [0.1212144  0.09822981 0.0950846  0.10754053 0.0910533  0.08915965\n",
      "  0.10546707 0.08408064 0.10322848 0.10494155]\n",
      " [0.11939172 0.09888238 0.09597007 0.0979322  0.08231191 0.10169146\n",
      "  0.09895449 0.10362191 0.10606793 0.09517589]\n",
      " [0.10678035 0.10447425 0.10150871 0.0980617  0.09818276 0.09917861\n",
      "  0.09939541 0.09272435 0.10334651 0.09634724]\n",
      " [0.10492045 0.1121157  0.09995599 0.09739656 0.09942887 0.09726822\n",
      "  0.08620629 0.10143581 0.10676163 0.09451049]\n",
      " [0.11232846 0.09518934 0.10659437 0.09825993 0.10081046 0.10584972\n",
      "  0.09519053 0.09186963 0.10640752 0.0875    ]\n",
      " [0.10316619 0.10855284 0.10272187 0.09009125 0.09319216 0.09413788\n",
      "  0.09517429 0.10183125 0.10469712 0.10643521]\n",
      " [0.10708507 0.10338521 0.10425557 0.11850169 0.09607075 0.09188989\n",
      "  0.09155855 0.09823692 0.08559004 0.10342632]\n",
      " [0.11446562 0.10658722 0.10196048 0.1068227  0.08645321 0.09886447\n",
      "  0.09320827 0.09825956 0.09545425 0.09792417]\n",
      " [0.10547169 0.09161363 0.10193225 0.09547828 0.10044312 0.09770032\n",
      "  0.11875793 0.09260636 0.09208561 0.10391081]\n",
      " [0.10408614 0.1129008  0.11128787 0.10020149 0.08585043 0.100991\n",
      "  0.10333107 0.09754273 0.09366457 0.090144  ]\n",
      " [0.0979869  0.11290514 0.0975792  0.09729104 0.09532385 0.10082188\n",
      "  0.09353909 0.09756105 0.10182166 0.10517018]\n",
      " [0.09621245 0.10563004 0.09774349 0.09988958 0.09614703 0.1034316\n",
      "  0.09842576 0.09815739 0.10321547 0.10114714]\n",
      " [0.10464466 0.1104984  0.0979035  0.10332303 0.09535151 0.09834027\n",
      "  0.09758423 0.10002016 0.09033661 0.10199761]] (102.659 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 0.504196\n",
      "INFO:tensorflow:probabilities = [[0.10609921 0.10167987 0.09553295 0.10301723 0.11116837 0.09295989\n",
      "  0.09588337 0.09783461 0.09655168 0.0992728 ]\n",
      " [0.10660495 0.1065634  0.09514769 0.10147663 0.100284   0.09970698\n",
      "  0.09086689 0.09753104 0.10508293 0.0967355 ]\n",
      " [0.11160638 0.09967358 0.09737933 0.10739765 0.08935992 0.08753562\n",
      "  0.09823395 0.10109878 0.10971569 0.09799904]\n",
      " [0.11102714 0.09104878 0.10521723 0.09972674 0.09033643 0.10078835\n",
      "  0.10308491 0.09605205 0.10563922 0.09707918]\n",
      " [0.10630025 0.09534957 0.09551922 0.10356397 0.09385126 0.09387089\n",
      "  0.10928044 0.09976465 0.10531443 0.09718534]\n",
      " [0.11871187 0.10509591 0.11029071 0.10791778 0.0950431  0.08332752\n",
      "  0.09546831 0.09058501 0.0940613  0.09949842]\n",
      " [0.09756466 0.10326674 0.09717186 0.09813087 0.10941326 0.09593491\n",
      "  0.09230756 0.10461731 0.09651837 0.10507445]\n",
      " [0.12584518 0.09925114 0.09918955 0.11054649 0.09276852 0.09123744\n",
      "  0.09690267 0.08042741 0.1050038  0.09882773]\n",
      " [0.12932202 0.09762217 0.09435546 0.11021898 0.08906199 0.0930002\n",
      "  0.09877668 0.0831323  0.10407365 0.10043658]\n",
      " [0.09779579 0.11013224 0.10228549 0.09592    0.08632795 0.09965926\n",
      "  0.09735052 0.09652043 0.10559621 0.10841215]\n",
      " [0.11212955 0.09628581 0.09648935 0.10465275 0.0954105  0.09119424\n",
      "  0.11077406 0.09418874 0.10530919 0.09356579]\n",
      " [0.09759779 0.09083737 0.09269287 0.10861225 0.10148168 0.09310842\n",
      "  0.1028017  0.0977931  0.10506199 0.11001287]\n",
      " [0.10196309 0.08912944 0.09814316 0.10808169 0.10050913 0.09936948\n",
      "  0.10538042 0.09318407 0.10608084 0.09815866]\n",
      " [0.10268919 0.10515673 0.09590038 0.10412746 0.09895017 0.09732098\n",
      "  0.10078487 0.09415118 0.09410775 0.10681129]\n",
      " [0.121891   0.10589091 0.09348514 0.10498407 0.0937131  0.09277399\n",
      "  0.10245156 0.09354431 0.10077295 0.09049293]\n",
      " [0.09751156 0.11832329 0.11185052 0.09738468 0.09140632 0.09696699\n",
      "  0.09198032 0.09975436 0.09907053 0.09575143]\n",
      " [0.10128363 0.10267425 0.10062353 0.11448295 0.08854198 0.09420583\n",
      "  0.10359359 0.08920493 0.11026233 0.09512705]\n",
      " [0.09955755 0.10488464 0.09900807 0.09453748 0.08882776 0.08757996\n",
      "  0.12431644 0.09369745 0.09983493 0.10775574]\n",
      " [0.10978483 0.09767345 0.0998074  0.09275638 0.09649644 0.09281341\n",
      "  0.12204804 0.09731744 0.09235366 0.098949  ]\n",
      " [0.1077382  0.11592237 0.09914158 0.10642629 0.09502591 0.0831657\n",
      "  0.0974955  0.09878264 0.10343756 0.09286427]\n",
      " [0.12776127 0.09504994 0.09825568 0.09618492 0.09419722 0.08379569\n",
      "  0.09915104 0.10649967 0.10229813 0.0968065 ]\n",
      " [0.10976274 0.09774186 0.10086617 0.10882846 0.09332856 0.0952752\n",
      "  0.09302999 0.09297005 0.10617761 0.10201945]\n",
      " [0.10386689 0.10688728 0.09789386 0.09596369 0.10077633 0.09092545\n",
      "  0.09750401 0.10508988 0.10101602 0.10007656]\n",
      " [0.10593587 0.10725626 0.09094135 0.12551573 0.08391669 0.09142812\n",
      "  0.09844771 0.10605998 0.09312329 0.09737495]\n",
      " [0.10619418 0.10657919 0.1040028  0.09596789 0.09121327 0.08830387\n",
      "  0.10484885 0.09238221 0.10933475 0.10117292]\n",
      " [0.11651528 0.09126274 0.08878595 0.10985408 0.10285768 0.10459284\n",
      "  0.10715634 0.08871435 0.09799332 0.09226742]\n",
      " [0.12179475 0.09267345 0.09194421 0.11423372 0.09488674 0.09374234\n",
      "  0.10646857 0.08574736 0.10499406 0.09351481]\n",
      " [0.09596002 0.10427775 0.1075908  0.09735677 0.09280294 0.10416468\n",
      "  0.09739956 0.0937173  0.10055835 0.10617184]\n",
      " [0.10497643 0.1108156  0.1049758  0.09026522 0.09290122 0.09888601\n",
      "  0.09776821 0.09694427 0.10851068 0.09395659]\n",
      " [0.126631   0.09657408 0.09620991 0.11138744 0.09644565 0.09355401\n",
      "  0.09146415 0.09430244 0.09097345 0.10245775]\n",
      " [0.10447559 0.1092677  0.09627862 0.11216456 0.09728236 0.09531056\n",
      "  0.10126166 0.10562125 0.09709512 0.08124255]\n",
      " [0.10780104 0.09989607 0.10930155 0.10322356 0.08681427 0.0951715\n",
      "  0.10551877 0.09238796 0.1007762  0.09910906]\n",
      " [0.11005262 0.09992762 0.1056358  0.11016795 0.09217299 0.10259374\n",
      "  0.09624605 0.09996839 0.09380962 0.0894252 ]\n",
      " [0.11470266 0.0978389  0.09562525 0.10705196 0.08398855 0.09060405\n",
      "  0.1072028  0.08627174 0.11172596 0.10498813]\n",
      " [0.10872454 0.10605445 0.09942964 0.10068998 0.09685192 0.10771385\n",
      "  0.08974085 0.09435796 0.10205423 0.09438252]\n",
      " [0.13465086 0.08943791 0.10012855 0.1056931  0.08305236 0.08937819\n",
      "  0.10962072 0.09789803 0.10027493 0.08986539]\n",
      " [0.09805513 0.099886   0.10974775 0.11535989 0.09357585 0.09396068\n",
      "  0.10366099 0.09129777 0.09506071 0.09939525]\n",
      " [0.11083064 0.10562695 0.09135003 0.08827978 0.09607998 0.09260714\n",
      "  0.10572357 0.09596628 0.11846604 0.09506959]\n",
      " [0.11860087 0.10358845 0.09907665 0.0941944  0.08734526 0.08245441\n",
      "  0.11399407 0.09644081 0.10963368 0.09467139]\n",
      " [0.1275802  0.09269215 0.09111986 0.11552545 0.08791562 0.09030554\n",
      "  0.09961477 0.08750419 0.09664277 0.11109948]\n",
      " [0.11791015 0.0935833  0.10848159 0.10384469 0.08926778 0.09379175\n",
      "  0.09384038 0.10275222 0.10760913 0.0889189 ]\n",
      " [0.10984019 0.09422003 0.10292498 0.09665701 0.09304195 0.09182709\n",
      "  0.10173561 0.10540254 0.10504413 0.09930651]\n",
      " [0.10139592 0.10459309 0.10682421 0.09300097 0.09255879 0.1058768\n",
      "  0.10336716 0.09368663 0.10338079 0.09531549]\n",
      " [0.11179513 0.09878031 0.10735692 0.09747488 0.0983348  0.09907501\n",
      "  0.08923028 0.09661179 0.09963966 0.10170121]\n",
      " [0.1039549  0.10687935 0.10111171 0.09488869 0.09603567 0.1030621\n",
      "  0.1002256  0.10178088 0.09328422 0.09877696]\n",
      " [0.11012024 0.11217183 0.09663999 0.09404793 0.09886377 0.09577568\n",
      "  0.09708813 0.09782371 0.10323603 0.09423266]\n",
      " [0.11670472 0.0978666  0.09841817 0.10485792 0.09641897 0.09468305\n",
      "  0.09956646 0.08416148 0.09979509 0.10752746]\n",
      " [0.1215932  0.08892838 0.09490639 0.1119079  0.08831343 0.10021191\n",
      "  0.10130363 0.08981577 0.10069717 0.10232227]\n",
      " [0.11554956 0.10599749 0.10638734 0.10291708 0.09668632 0.08788346\n",
      "  0.10272262 0.09271741 0.09800354 0.09113517]\n",
      " [0.10340188 0.10844507 0.09606162 0.10272236 0.09338722 0.10140173\n",
      "  0.09096832 0.09811732 0.10031078 0.10518371]\n",
      " [0.10664514 0.09754939 0.10306533 0.10108677 0.09091349 0.08994005\n",
      "  0.09725632 0.09916675 0.11029479 0.10408188]\n",
      " [0.12947322 0.10280655 0.08853355 0.10223132 0.08783378 0.09287863\n",
      "  0.10591498 0.07349896 0.11967064 0.09715839]\n",
      " [0.11691419 0.09292419 0.09900711 0.09314318 0.10440367 0.1040407\n",
      "  0.09706934 0.10208714 0.09764223 0.09276834]\n",
      " [0.12977679 0.09958927 0.11006239 0.10965708 0.08872733 0.08847377\n",
      "  0.09639283 0.08345848 0.09818383 0.09567814]\n",
      " [0.11004961 0.10436115 0.09578273 0.10117187 0.09220541 0.0901788\n",
      "  0.10708874 0.09779432 0.10122529 0.10014192]\n",
      " [0.1071485  0.09979548 0.09587432 0.09399696 0.09564331 0.10169234\n",
      "  0.09459541 0.10882533 0.09201354 0.11041479]\n",
      " [0.14227593 0.09877454 0.0825257  0.09875244 0.08197653 0.08544989\n",
      "  0.10819375 0.09119619 0.11078631 0.10006879]\n",
      " [0.11010622 0.10433652 0.09896696 0.09866087 0.08951621 0.10074582\n",
      "  0.10051779 0.10592851 0.09827223 0.09294882]\n",
      " [0.12840892 0.10633887 0.09582359 0.10376811 0.09004943 0.08836196\n",
      "  0.10393646 0.10210823 0.09192671 0.08927767]\n",
      " [0.09688047 0.10577499 0.10006259 0.10601193 0.08986168 0.09871996\n",
      "  0.09504928 0.09445107 0.10725792 0.10593013]\n",
      " [0.11267603 0.09935632 0.10218566 0.1141467  0.08942117 0.08983731\n",
      "  0.10067971 0.10100656 0.10358781 0.08710281]\n",
      " [0.09839107 0.11522426 0.09783054 0.1027379  0.09847036 0.09622334\n",
      "  0.0937399  0.10017619 0.10028377 0.09692269]\n",
      " [0.1126229  0.11043596 0.10469659 0.0993467  0.08211122 0.09340612\n",
      "  0.08944742 0.09919368 0.10599983 0.10273954]\n",
      " [0.11239476 0.11036492 0.09894368 0.10216226 0.09088159 0.08869429\n",
      "  0.10658269 0.08423105 0.10513947 0.10060529]\n",
      " [0.11072304 0.0926526  0.10255465 0.10456494 0.08752039 0.10028911\n",
      "  0.10914712 0.08277865 0.11115785 0.09861155]\n",
      " [0.10591781 0.10742467 0.09542237 0.08927213 0.09431679 0.11420845\n",
      "  0.10101105 0.08876637 0.10449742 0.09916285]\n",
      " [0.11314359 0.10648726 0.10359636 0.09671687 0.08470023 0.09479734\n",
      "  0.09786522 0.08735353 0.11579563 0.09954399]\n",
      " [0.1025973  0.10883361 0.09902515 0.09838347 0.09598502 0.08625037\n",
      "  0.10083852 0.09756424 0.09770267 0.1128197 ]\n",
      " [0.10019031 0.09496743 0.10071125 0.10192087 0.10134968 0.0930145\n",
      "  0.09543825 0.09386196 0.10503799 0.1135077 ]\n",
      " [0.12855332 0.09547169 0.09502808 0.11554859 0.07807191 0.09340243\n",
      "  0.09534007 0.09051422 0.10427937 0.10379036]\n",
      " [0.11657852 0.10120651 0.08379157 0.10631507 0.09509062 0.09152545\n",
      "  0.10089954 0.10951246 0.09605462 0.09902562]\n",
      " [0.10157724 0.10816837 0.10455015 0.12710346 0.08711184 0.09558937\n",
      "  0.09701663 0.09770178 0.0849748  0.09620643]\n",
      " [0.09942354 0.10258952 0.10460301 0.10880828 0.09831773 0.08926043\n",
      "  0.08994849 0.10011963 0.10214623 0.10478312]\n",
      " [0.10635688 0.10225593 0.09278461 0.10741903 0.0995058  0.09210601\n",
      "  0.09224083 0.09623162 0.10753237 0.10356692]\n",
      " [0.13306849 0.09336456 0.09893964 0.09511461 0.08379287 0.09518352\n",
      "  0.10512429 0.08850144 0.11074619 0.09616436]\n",
      " [0.10046133 0.10201006 0.10110731 0.10734091 0.09639227 0.09031747\n",
      "  0.09102562 0.10244679 0.10727798 0.10162023]\n",
      " [0.12688908 0.09986235 0.10868849 0.10048813 0.08844735 0.0990888\n",
      "  0.10220389 0.09210913 0.09435047 0.08787237]\n",
      " [0.11513385 0.11565922 0.09714775 0.09432405 0.09104261 0.09079126\n",
      "  0.10332015 0.10132245 0.10388077 0.08737786]\n",
      " [0.1040381  0.10370076 0.09878912 0.09667104 0.09760335 0.09402776\n",
      "  0.08995929 0.10528763 0.11209783 0.09782507]\n",
      " [0.09635782 0.11598343 0.09517508 0.10177354 0.08891036 0.09650821\n",
      "  0.10319035 0.09926908 0.10637308 0.09645912]\n",
      " [0.10814851 0.11053843 0.08919765 0.12039527 0.085868   0.09635124\n",
      "  0.09283759 0.09651857 0.09762614 0.10251858]\n",
      " [0.11007025 0.10688156 0.0909308  0.09948311 0.09698839 0.09431932\n",
      "  0.09755147 0.09410844 0.11067572 0.09899099]\n",
      " [0.10857241 0.1023047  0.08834338 0.097854   0.09786767 0.10477696\n",
      "  0.10288308 0.09048185 0.11079763 0.09611833]\n",
      " [0.10638599 0.11068711 0.09428945 0.08978221 0.09498525 0.09882712\n",
      "  0.09804615 0.10763624 0.10280956 0.09655086]\n",
      " [0.10052035 0.10455929 0.10260186 0.10191339 0.09572412 0.10117347\n",
      "  0.09667434 0.09694849 0.10420521 0.09567954]\n",
      " [0.10890801 0.10466721 0.11100726 0.09509211 0.09423161 0.09399877\n",
      "  0.09734785 0.09096652 0.10539814 0.0983826 ]\n",
      " [0.10411841 0.09950174 0.10177791 0.10375949 0.10475225 0.09972797\n",
      "  0.09210116 0.10694433 0.09334952 0.09396723]\n",
      " [0.11093512 0.10059406 0.09587136 0.09622195 0.09701174 0.09504905\n",
      "  0.09012683 0.10142953 0.10850516 0.10425518]\n",
      " [0.1020551  0.09887497 0.10128453 0.10814039 0.09082747 0.09240559\n",
      "  0.104791   0.10387277 0.10375259 0.09399556]\n",
      " [0.10780002 0.10593518 0.09767702 0.09543189 0.09824735 0.09216496\n",
      "  0.10297741 0.10213062 0.1027494  0.09488614]\n",
      " [0.11572206 0.09571765 0.09394684 0.1123216  0.0970175  0.10170459\n",
      "  0.08619425 0.09929708 0.10014741 0.09793099]\n",
      " [0.10526752 0.10522576 0.10133374 0.11034634 0.09210034 0.0823321\n",
      "  0.10115374 0.1029011  0.10038117 0.0989582 ]\n",
      " [0.11814681 0.10406619 0.10216396 0.0914219  0.10573871 0.09327012\n",
      "  0.09210948 0.09479713 0.09081029 0.10747541]\n",
      " [0.10883169 0.09782783 0.0956156  0.09557122 0.0835443  0.09360094\n",
      "  0.10292605 0.10421222 0.11838426 0.09948593]\n",
      " [0.14899737 0.09717981 0.08343127 0.10911494 0.08137324 0.07912374\n",
      "  0.10541445 0.09438024 0.09979264 0.10119238]\n",
      " [0.09986753 0.10641092 0.10038117 0.09951351 0.09494291 0.09564556\n",
      "  0.08532231 0.10581751 0.10899068 0.103108  ]\n",
      " [0.11048441 0.10453053 0.09780796 0.09573173 0.1018021  0.08634192\n",
      "  0.09727456 0.09984719 0.10924987 0.09692974]\n",
      " [0.10638656 0.10465255 0.10281381 0.10426176 0.0868519  0.09329534\n",
      "  0.09248476 0.10660529 0.10825245 0.09439562]\n",
      " [0.11635661 0.09591722 0.09885055 0.10325694 0.09864933 0.09195895\n",
      "  0.10394663 0.09127397 0.10872988 0.09105986]\n",
      " [0.10947914 0.09363354 0.09463186 0.10245357 0.10134363 0.09559944\n",
      "  0.10857385 0.08643407 0.11432743 0.09352342]] (95.690 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.229753, step = 301 (198.352 sec)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-ea85579ca168>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#Changing steps back to 20000 in model training results in an accuracy of 97%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\7178185\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(main, argv)\u001b[0m\n\u001b[0;32m    123\u001b[0m   \u001b[1;31m# Call the main function, passing through any arguments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m   \u001b[1;31m# to the final program.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m   \u001b[0m_sys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-2c8f4bafec7a>\u001b[0m in \u001b[0;36mmain\u001b[1;34m(unused_argv)\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0minput_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_input_fn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         hooks=[logging_hook])\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;31m# Evaluate the model and print results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\7178185\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[0;32m    374\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 376\u001b[1;33m       \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    377\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loss for final step: %s.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\7178185\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1143\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1144\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1145\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1147\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\7178185\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1171\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[0;32m   1172\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1173\u001b[1;33m                                              saving_listeners)\n\u001b[0m\u001b[0;32m   1174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1175\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_train_model_distributed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\7178185\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_with_estimator_spec\u001b[1;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[0;32m   1449\u001b[0m       \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1450\u001b[0m       \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1451\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1452\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\7178185\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    581\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m                           run_metadata=run_metadata)\n\u001b[0m\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\7178185\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1057\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1058\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1059\u001b[1;33m                               run_metadata=run_metadata)\n\u001b[0m\u001b[0;32m   1060\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1061\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[1;32mc:\\users\\7178185\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1133\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1135\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\7178185\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1205\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1206\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1207\u001b[1;33m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[0;32m   1208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1209\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\7178185\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    986\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 987\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    988\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    989\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_with_hooks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\7178185\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    875\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 877\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    878\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\7178185\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1098\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1100\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1101\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\7178185\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1270\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1272\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1273\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1274\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\7178185\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1276\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1277\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1278\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1279\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1280\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\7178185\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1261\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1263\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1265\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\7178185\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Run the model, steps set to 200 instead of 20000 as the execution time was large\n",
    "#Changing steps back to 20000 in model training results in an accuracy of 97%\n",
    "if __name__ == \"__main__\":\n",
    "    tf.app.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
